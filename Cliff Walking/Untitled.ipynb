{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:27:02.708425Z",
     "start_time": "2018-10-31T21:27:02.679385Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "\n",
    "from operator import add\n",
    "\n",
    "\n",
    "from IPython.core.debugger import set_trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:36:06.866873Z",
     "start_time": "2018-10-31T21:36:06.712962Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REWARD_NONTERMINAL = -1\n",
    "REWARD_TERMINAL = 10\n",
    "REWARD_CLIFF = -100\n",
    "ACTION_DIRECTIONS = [(0, 1), (1, 0), (0, -1), (-1, 0)]\n",
    "\n",
    "class Environment:\n",
    "\n",
    "    def __init__(self, nr_columns, nr_rows, nr_actions=4, init_qa_values=0):\n",
    "        self.world = np.zeros((nr_rows, nr_columns))\n",
    "        self.nr_columns = nr_columns\n",
    "        self.nr_rows = nr_rows\n",
    "        self.nr_actions = nr_actions\n",
    "        \n",
    "    def set_world_rewards(self):\n",
    "        pass\n",
    "    \n",
    "    def is_out_of_bounds(self, state):\n",
    "        if state[0] < 0 or state[0] > self.nr_rows - 1:\n",
    "            return True\n",
    "        \n",
    "        if state[1] < 0 or state[1] > self.nr_columns -1:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def next_state(self, state, action):\n",
    "        pass\n",
    "    \n",
    "    def check_termination(self, state):\n",
    "        pass\n",
    "\n",
    "class CliffEnvironment(Environment):\n",
    "    \n",
    "    def __init__(self, nr_columns, nr_rows, nr_actions=4, init_qa_values=0):\n",
    "        super().__init__(nr_columns, nr_rows)\n",
    "        self.set_world_rewards()\n",
    "        \n",
    "    def set_world_rewards(self):\n",
    "        self.world[:, :] = REWARD_NONTERMINAL\n",
    "        self.world[self.nr_rows - 1:, 1:self.nr_columns - 1] = REWARD_CLIFF\n",
    "        self.world[self.nr_rows - 1, self.nr_columns - 1] = REWARD_TERMINAL\n",
    "        \n",
    "    def next_state(self, state, action_index):\n",
    "        action = ACTION_DIRECTIONS[action_index]\n",
    "        next_state = tuple(map(add, state, action))\n",
    "        \n",
    "        if self.is_out_of_bounds(next_state):\n",
    "            next_state = state\n",
    "        \n",
    "        return next_state\n",
    "    \n",
    "    def check_termination(self, state):\n",
    "        return state[1] == self.nr_rows - 1 and state[0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:41:39.168777Z",
     "start_time": "2018-10-31T21:41:38.923547Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALPHA = 0.1\n",
    "GAMMA = 1\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, env, epsilon=0.2, init_position=(0,0)):\n",
    "        self.init_position = init_position\n",
    "        self.curr_state = init_position\n",
    "        self.env = env\n",
    "        self.epsilon = epsilon\n",
    "        self.q_table = np.zeros((env.nr_columns, env.nr_rows + 1, env.nr_actions))\n",
    "        \n",
    "    def run(self):\n",
    "        pass\n",
    "    \n",
    "    def get_next_action(self):\n",
    "        \"\"\"Returns the next index of the action according to the epsilon-greedy choice\"\"\"\n",
    "        actions = self.q_table[self.curr_state]\n",
    "        \n",
    "        # If we choose randomly\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return np.random.choice(4)\n",
    "        \n",
    "        return np.argmax(actions)\n",
    "    \n",
    "    def get_next_state(self, action):\n",
    "        \"\"\"Return next theoretical state according to the environment.\"\"\"\n",
    "        return self.env.next_state(self.curr_state, action)\n",
    "    \n",
    "    def update_q_table(self, action, next_state, next_best_action):\n",
    "        pass\n",
    "    \n",
    "    def get_reward_for_state(self, state):\n",
    "        return self.env.world.transpose()[state]\n",
    "    \n",
    "    def terminated(self):\n",
    "        set_trace()\n",
    "        return self.env.check_termination(self.curr_state)\n",
    "    \n",
    "    def update_state(self, next_state):\n",
    "        self.curr_state = next_state\n",
    "        \n",
    "class QLearner(Agent):\n",
    "    def __init__(self, env, nr_episodes, epsilon=0.2 , init_position=(0,0)):\n",
    "        super().__init__(env, epsilon, init_position)\n",
    "        self.nr_episodes = nr_episodes\n",
    "        \n",
    "    def run(self):\n",
    "        for i in range(self.nr_episodes):\n",
    "            self.curr_state = self.init_position\n",
    "            \n",
    "            while not self.terminated():\n",
    "                action_index = self.get_next_action()\n",
    "                next_state = self.get_next_state(action_index)\n",
    "                next_state_best_action_index = np.argmax(self.q_table[next_state])\n",
    "\n",
    "                self.update_q_table(action_index, next_state, next_state_best_action_index)\n",
    "                self.update_state(next_state)\n",
    "                \n",
    "    def update_q_table(self, action_index, next_state, next_best_action_index):\n",
    "        curr_q = self.q_table[self.curr_state][action_index]\n",
    "        update = (self.get_reward_for_state(next_state) + GAMMA * self.q_table[next_state][next_best_action_index] - curr_q)\n",
    "        self.q_table[self.curr_state][action_index] = curr_q + ALPHA * update\n",
    "        \n",
    "    \n",
    "class SarsaLearner(Agent):\n",
    "    def __init__(self, env, nr_episodes, epsilon=0.2, init_position=(0,0)):\n",
    "        super().__init__(env, init_position)\n",
    "        self.nr_episodes = nr_episodes\n",
    "        \n",
    "    def run(self):\n",
    "        for i in range(self.nr_episodes):\n",
    "            pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:41:41.507045Z",
     "start_time": "2018-10-31T21:41:41.496130Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "# Main Run - Initialization\n",
    "###\n",
    "NR_COLUMNS = 5\n",
    "\n",
    "# Including the cliff\n",
    "NR_ROWS = 4\n",
    "\n",
    "cliffWorld = CliffEnvironment(NR_COLUMNS, NR_ROWS)\n",
    "agent = QLearner(cliffWorld, 100, 0.2, (0, NR_ROWS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:42:09.024084Z",
     "start_time": "2018-10-31T21:41:54.985147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-18-f7e87a280039>\u001b[0m(37)\u001b[0;36mterminated\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     35 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     36 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 37 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_termination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     39 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> self.env.check_termination(self.curr_state)\n",
      "False\n",
      "ipdb> self.curr_state\n",
      "(0, 4)\n",
      "ipdb> c\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 1 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-03d8e5d2e7e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-f7e87a280039>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mnext_state_best_action_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_q_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state_best_action_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-f7e87a280039>\u001b[0m in \u001b[0;36mupdate_q_table\u001b[0;34m(self, action_index, next_state, next_best_action_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_q_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_best_action_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mcurr_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reward_for_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGAMMA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_best_action_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurr_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_q\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mALPHA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-f7e87a280039>\u001b[0m in \u001b[0;36mget_reward_for_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_reward_for_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 1 with size 4"
     ]
    }
   ],
   "source": [
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:24:03.340472Z",
     "start_time": "2018-10-31T21:24:03.328785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 1.26625651e+05,  0.00000000e+00,  0.00000000e+00,\n",
       "          3.63495324e+03],\n",
       "        [ 1.53607802e+06,  0.00000000e+00, -1.00000000e-01,\n",
       "          0.00000000e+00],\n",
       "        [ 2.84297523e+06,  3.90024330e+05,  2.86302610e+05,\n",
       "          9.85181610e+05],\n",
       "        [ 1.89412752e+06,  3.01021348e+06,  2.13826911e+06,\n",
       "          2.46569319e+06]],\n",
       "\n",
       "       [[ 8.83232395e+04,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 1.62684834e+06,  4.26151034e+04, -1.00000000e-01,\n",
       "          3.63495324e+03],\n",
       "        [ 2.83835647e+06,  1.31182903e+06,  6.82459874e+05,\n",
       "          3.33303931e+05],\n",
       "        [ 2.80155104e+06,  3.02441243e+06,  2.61618305e+06,\n",
       "          2.58617473e+06],\n",
       "        [ 3.00703375e+06,  3.03879785e+06,  2.97406177e+06,\n",
       "          2.96463275e+06]],\n",
       "\n",
       "       [[ 4.99312956e+05,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 2.77809546e+06,  1.02531923e+06,  5.45897676e+04,\n",
       "          4.60803319e+05],\n",
       "        [ 3.01935106e+06,  2.63281104e+06,  2.37730153e+06,\n",
       "          2.38829530e+06],\n",
       "        [ 3.03953525e+06,  3.01541462e+06,  2.98705111e+06,\n",
       "          3.00759165e+06],\n",
       "        [ 3.03808655e+06,  3.04097156e+06,  3.03671978e+06,\n",
       "          3.03605075e+06]],\n",
       "\n",
       "       [[ 1.79094462e+06,  0.00000000e+00,  3.48679422e+04,\n",
       "          1.06187083e+04],\n",
       "        [ 2.99943806e+06,  2.20215398e+06,  8.63761156e+05,\n",
       "          2.06781195e+06],\n",
       "        [ 3.03781115e+06,  2.99121367e+06,  2.95947166e+06,\n",
       "          2.95443125e+06],\n",
       "        [ 3.04094647e+06,  3.03802654e+06,  3.03485527e+06,\n",
       "          3.03590740e+06],\n",
       "        [ 3.04106600e+06,  3.04079468e+06,  3.04067501e+06,\n",
       "          3.04082856e+06]],\n",
       "\n",
       "       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.q_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
